{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "src = pathlib.Path().absolute().parent\n",
    "\n",
    "sys.path.append(str(src))\n",
    "\n",
    "from src.models.segmentation.unet import UNet\n",
    "from src.data.segmentation import BoxSegmentationDataset, LGGSegmentationDataset \n",
    "from src.enums import DataSplit\n",
    "from src.data.datasets import LGG_NORMALIZE_TRANSFORM\n",
    "from src.utils.transforms import DualInputCompose, DualInputResize, DualInputTransform, ImgOnlyTransform\n",
    "from src.utils.visualize import plot_semantic_predictions\n",
    "\n",
    "LOG_DIR = src / 'logs'\n",
    "MODEL_REGISTRY = src / 'model_registry'\n",
    "DATASETS = src / 'datasets'\n",
    "\n",
    "base_transforms = DualInputCompose([DualInputResize((320, 320)), DualInputTransform(T.ToTensor())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_test(type: str, path: pathlib.Path, normalized: bool = False, transforms: DualInputCompose = base_transforms):\n",
    "    model = UNet.load(path)\n",
    "    if type == \"box\":\n",
    "        dataset = BoxSegmentationDataset(root_dir=DATASETS, split=DataSplit.TEST, transform=transforms)\n",
    "    elif type == \"lgg\":\n",
    "        if normalized:\n",
    "            transforms = DualInputCompose([*transforms.transforms, ImgOnlyTransform(LGG_NORMALIZE_TRANSFORM)])\n",
    "            \n",
    "        dataset = LGGSegmentationDataset(root_dir=DATASETS, split=DataSplit.TEST, transform=transforms)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid type\")\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=6, shuffle=False)\n",
    "    model.eval()\n",
    "    imgs, masks = next(iter(loader))\n",
    "    preds = model(imgs)\n",
    "    preds = preds.sigmoid().round().int()\n",
    "    plot_semantic_predictions(imgs, masks, preds, include_overlay=True, include_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgg_score = 0\n",
    "lgg_metrics = None\n",
    "best_lgg_norm_score = 0\n",
    "lgg_metrics_norm = None\n",
    "best_box_score = 0\n",
    "box_metrics = None\n",
    "\n",
    "best_lgg = None\n",
    "best_lgg_norm = None\n",
    "best_box = None\n",
    "\n",
    "for exp_dir in MODEL_REGISTRY.iterdir():\n",
    "    # check if run_dir is actually a directory\n",
    "    if not exp_dir.is_dir():\n",
    "        continue\n",
    "    for run_dir in exp_dir.iterdir():\n",
    "        exp_path = str(run_dir).split('model_registry/')[-1]\n",
    "        metric_path = LOG_DIR / exp_path / 'metrics.json'\n",
    "        if not metric_path.exists():\n",
    "            continue\n",
    "        with open(metric_path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        check_points = list(run_dir.glob(\"*.pth\"))\n",
    "        steps = [int(check_point.stem.split(\"_\")[-1]) for check_point in check_points]\n",
    "        for i, step in enumerate(steps):\n",
    "            step = str(step)\n",
    "            if 'lgg' in exp_path and metrics.get(str(step)) is not None:\n",
    "                if 'normalized' in exp_path:\n",
    "                    if metrics[step]['val_BinaryIoU'] > best_lgg_norm_score:\n",
    "                        best_lgg_norm_score = metrics[step]['val_BinaryIoU']\n",
    "                        best_lgg_norm = check_points[i]\n",
    "                        lgg_metrics_norm = metrics[step]\n",
    "                elif metrics[step]['val_BinaryIoU']> best_lgg_score:\n",
    "                    best_lgg_score = metrics[step]['val_BinaryIoU']\n",
    "                    best_lgg = check_points[i]\n",
    "                    lgg_metrics = metrics[step]\n",
    "            elif 'box' in exp_path and metrics.get(str(step)) is not None:\n",
    "                if metrics[step]['val_BinaryIoU']> best_box_score:\n",
    "                    best_box_score = metrics[step]['val_BinaryIoU']\n",
    "                    print(metrics[step]['val_BinaryAUROC'])\n",
    "                    best_box = check_points[i]\n",
    "                    box_metrics = metrics[step]\n",
    "\n",
    "\n",
    "print(f\"Best LGG Path: {best_lgg} \\nMetrics: {lgg_metrics}\")\n",
    "print(f\"Best LGG Normalized Path: {best_lgg_norm} \\nMetrics: {lgg_metrics_norm}\")\n",
    "print(f\"Best Box Path: {best_box}\\nMetrics: {box_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_test(\"lgg\", best_lgg)\n",
    "load_and_test(\"lgg\", best_lgg_norm, normalized=True)\n",
    "load_and_test(\"box\", best_box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
